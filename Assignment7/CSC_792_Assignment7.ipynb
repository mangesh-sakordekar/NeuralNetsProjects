{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74defdf6-8850-47dc-ba5c-13f291ec680f",
   "metadata": {},
   "source": [
    "# CSC 792 Assignment 7 - Movie Rating Regression\n",
    "\n",
    "## Mangesh Sakordekar (7440013)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a2e88-e0f1-4e8e-a537-b9d41183f43d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a494b21c-dfba-42e5-9c59-6eb74be2b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02845e81-c303-4d87-818b-b5f86503a17f",
   "metadata": {},
   "source": [
    "#### Directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a4b94-795f-42d1-b9d4-b2098ad309fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If val directory does not exist, run the following code to create one\n",
    "'''\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1337).shuffle(files)\n",
    "    num_val_samples = int(0.2 * len(files))\n",
    "    val_files = files[-num_val_samples:]\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir / category / fname,\n",
    "                    val_dir / category / fname)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a5720-47eb-47dd-b2a4-7a1f5e869d5c",
   "metadata": {},
   "source": [
    "### Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd3649ff-774e-454b-b614-fcab04ab17f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'aclImdb'  \n",
    "\n",
    "def load_data(directory):\n",
    "    reviews = []\n",
    "    ratings = []\n",
    "    for category in ['pos', 'neg']:\n",
    "        path = os.path.join(directory, category)\n",
    "        for filename in os.listdir(path):\n",
    "            if filename.endswith('.txt'):\n",
    "                with open(os.path.join(path, filename), 'r', encoding='utf-8') as file:\n",
    "                    review = file.read()\n",
    "                    reviews.append(review)\n",
    "                    # Extract the rating from the filename\n",
    "                    rating = int(filename.split('_')[-1].split('.')[0])\n",
    "                    ratings.append(rating)\n",
    "    return reviews, ratings\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "\n",
    "# Load train and test data\n",
    "train_reviews, train_ratings = load_data(train_dir)\n",
    "test_reviews, test_ratings = load_data(test_dir)\n",
    "val_reviews, val_ratings = load_data(test_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672717f-2c21-45f5-ad0f-d8f6d3de39a9",
   "metadata": {},
   "source": [
    "### Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f5eaf2b-d4b1-4eb3-8f51-f72f330ca3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\", batch_size=batch_size\n",
    ")\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c604e3e-ad2e-48d9-9f00-92e111466242",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length,\n",
    ")\n",
    "text_vectorization.adapt(text_only_train_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91cf4b84-dd6a-4ab3-8e26-d7312845e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews_vectorized = text_vectorization(train_reviews)\n",
    "test_reviews_vectorized = text_vectorization(test_reviews)\n",
    "val_reviews_vectorized = text_vectorization(val_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7cafe9-b771-4cf2-b0f1-e320b0a9cf6d",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d85cc42c-e1ec-4e9a-ab63-201d4512c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the data to numpy arrays\n",
    "train_data = np.array(train_reviews_vectorized)\n",
    "train_labels = np.array(train_ratings).astype(float)\n",
    "test_data = np.array(test_reviews_vectorized)\n",
    "test_labels = np.array(test_ratings).astype(float)\n",
    "val_data = np.array(val_reviews_vectorized)\n",
    "val_labels = np.array(val_ratings).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d7734f-070d-414a-ab1c-f7c9959f538b",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "af4c1198-7db2-4782-bd01-a41ac74007a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_14 (Embedding)    (None, None, 64)          1280000   \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (None, 64)               24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,304,897\n",
      "Trainable params: 1,304,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "625/625 [==============================] - 207s 320ms/step - loss: 8.6084 - mae: 2.3803 - val_loss: 5.4367 - val_mae: 1.8100\n",
      "Epoch 2/15\n",
      "625/625 [==============================] - 208s 334ms/step - loss: 4.9825 - mae: 1.7073 - val_loss: 5.5625 - val_mae: 1.7775\n",
      "Epoch 3/15\n",
      "625/625 [==============================] - 201s 322ms/step - loss: 4.0256 - mae: 1.5093 - val_loss: 4.3889 - val_mae: 1.5849\n",
      "Epoch 4/15\n",
      "625/625 [==============================] - 201s 322ms/step - loss: 3.4720 - mae: 1.3982 - val_loss: 4.4755 - val_mae: 1.6088\n",
      "Epoch 5/15\n",
      "625/625 [==============================] - 206s 330ms/step - loss: 3.0395 - mae: 1.3029 - val_loss: 4.9778 - val_mae: 1.6467\n",
      "Epoch 6/15\n",
      "625/625 [==============================] - 202s 324ms/step - loss: 2.6389 - mae: 1.1993 - val_loss: 4.5657 - val_mae: 1.5144\n",
      "Epoch 7/15\n",
      "625/625 [==============================] - 210s 336ms/step - loss: 2.2438 - mae: 1.1058 - val_loss: 5.2762 - val_mae: 1.6770\n",
      "Epoch 8/15\n",
      "625/625 [==============================] - 203s 325ms/step - loss: 2.0151 - mae: 1.0439 - val_loss: 4.8575 - val_mae: 1.5601\n",
      "Epoch 9/15\n",
      "625/625 [==============================] - 205s 328ms/step - loss: 1.7885 - mae: 0.9800 - val_loss: 4.8912 - val_mae: 1.5561\n",
      "Epoch 10/15\n",
      "625/625 [==============================] - 202s 323ms/step - loss: 1.6029 - mae: 0.9282 - val_loss: 4.7474 - val_mae: 1.5736\n",
      "Epoch 11/15\n",
      "625/625 [==============================] - 208s 333ms/step - loss: 1.4310 - mae: 0.8777 - val_loss: 4.8815 - val_mae: 1.5455\n",
      "Epoch 12/15\n",
      "625/625 [==============================] - 204s 327ms/step - loss: 1.2865 - mae: 0.8302 - val_loss: 4.9545 - val_mae: 1.5993\n",
      "Epoch 13/15\n",
      "625/625 [==============================] - 211s 338ms/step - loss: 1.1697 - mae: 0.7906 - val_loss: 5.2523 - val_mae: 1.6436\n",
      "Epoch 14/15\n",
      "625/625 [==============================] - 203s 324ms/step - loss: 1.0624 - mae: 0.7564 - val_loss: 5.0303 - val_mae: 1.6319\n",
      "Epoch 15/15\n",
      "625/625 [==============================] - 208s 333ms/step - loss: 0.9849 - mae: 0.7305 - val_loss: 5.1729 - val_mae: 1.6132\n",
      "782/782 [==============================] - 76s 90ms/step - loss: 4.3889 - mae: 1.5849\n",
      "Test MAE: 1.58\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded = layers.Embedding(\n",
    "    input_dim=max_tokens, output_dim=64, mask_zero=True)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "outputs = layers.Dense(1, activation=\"selu\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"mse\",\n",
    "              metrics=[\"mae\"])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"embeddings.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "history = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), \n",
    "                    epochs=15, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"embeddings.keras\")\n",
    "print(f\"Test MAE: {model.evaluate(test_data, test_labels)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c036b740-540c-4234-bbc3-04a12d448042",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fa9d5d2b-add9-488e-9831-acad4aa2aaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted rating: 5.858356\tactual rating: 9.0\n",
      "predicted rating: 5.400948\tactual rating: 7.0\n",
      "predicted rating: 8.505113\tactual rating: 7.0\n",
      "predicted rating: 3.4114602\tactual rating: 4.0\n",
      "predicted rating: 8.419339\tactual rating: 8.0\n",
      "predicted rating: 8.477797\tactual rating: 10.0\n",
      "predicted rating: 3.3568032\tactual rating: 3.0\n",
      "predicted rating: 8.123314\tactual rating: 10.0\n",
      "predicted rating: 9.6205435\tactual rating: 9.0\n",
      "predicted rating: 1.3601909\tactual rating: 1.0\n"
     ]
    }
   ],
   "source": [
    "random_ind = [random.randint(0, 25000) for _ in range(10)]\n",
    "for i in random_ind:\n",
    "    print(\"predicted rating: \" + str(model.predict(np.reshape(test_data[i, :], (1,600,1)), verbose=0)[0][0])\n",
    "          + \"\\tactual rating: \" + str(test_labels[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
